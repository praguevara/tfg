% Encoding: UTF-8

@inproceedings{alldieck2019tex2shape,
  author       = {Alldieck, Thiemo and Pons-Moll, Gerard and Theobalt, Christian and Magnor, Marcus},
  booktitle    = {{IEEE} International Conference on Computer Vision ({ICCV})},
  organization = {{IEEE}},
  title        = {Tex2Shape: Detailed Full Human Body Geometry from a Single Image},
  year         = {2019}
}

@article{allen:2003,
  author  = {Allen, Brett and Curless, Brian and Popovic, Zoran},
  doi     = {10.1145/1201775.882311},
  journal = {ACM Trans. Graph.},
  month   = {07},
  pages   = {587-594},
  title   = {The Space of Human Body Shapes: Reconstruction and Parameterization from Range Scans},
  volume  = {22},
  year    = {2003}
}

@article{apeagyei2010application,
  author  = {Apeagyei, Phoebe},
  doi     = {10.4156/jdcta.vol4.issue7.6},
  journal = {JDCTA},
  month   = {10},
  pages   = {58-68},
  title   = {Application of 3D body scanning technology to human measurement for clothing Fit.},
  volume  = {4},
  year    = {2010}
}

@misc{attention:2017,
  archiveprefix = {arXiv},
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  eprint        = {1706.03762},
  primaryclass  = {cs.CL},
  title         = {Attention Is All You Need},
  year          = {2017}
}

@article{Azorin-Lopez2020,
  author  = {Fuster-Guilló,Andrés and Azorín-López, Jorge and Saval-Calvo, Marcelo and Castillo Zaragoza, Juan Miguel and Garcia-D'Urso, Nahuel and Fisher, Robert B.},
  doi     = {10.3390/s20133690},
  journal = {Sensors 2020},
  month   = {jul},
  title   = {{RGB-D-Based Framework to Acquire, Visualize and Measure the Human Body for Dietetic Treatments}},
  url     = {https://www.mdpi.com/1424-8220/20/13/3690/pdf},
  year    = {2020}
}


@inproceedings{blendscape,
  author = {Hirshberg, David and Loper, Matthew and Rachlin, Eric and Black, Michael},
  doi    = {10.1007/978-3-642-33783-3_18},
  isbn   = {978-3-642-33782-6},
  month  = {10},
  pages  = {242-255},
  title  = {Coregistration: Simultaneous Alignment and Modeling of Articulated 3D Shape},
  volume = {7577},
  year   = {2012}
}

@article{CHEN201952,
  abstract = {To realistically represent 3D human body shape in a mathematical way, the parametric model used should incorporate symmetry as displayed by real people. This paper proposes a symmetric parametric model called symmetricSCAPE. It successfully incorporates symmetry into a parametric model of the 3D body, formulating body geometric variations of both shape and pose using a triangular mesh representation. The symmetry constraint is imposed on each symmetrically-related triangle pair of the body mesh. Mathematically, symmetry-related constraint matrices are derived, and applied during shape and pose deformation of triangle pairs. By accurately registering a pre-designed symmetrization template mesh to the training dataset, we learn how the symmetricSCAPE model causes the body mesh to deform relative to the symmetry. Our experiments demonstrate that the symmetricSCAPE model results in a better, more parsimonious, and more accurate parametric model of the 3D human body than traditional non-symmetry-aware representations.},
  author   = {Yin Chen and Zhan Song and Weiwei Xu and Ralph R. Martin and Zhi-Quan Cheng},
  doi      = {https://doi.org/10.1016/j.cag.2019.03.013},
  issn     = {0097-8493},
  journal  = {Computers \& Graphics},
  keywords = {3D human body, Symmetry, Shape, Pose, Accuracy},
  pages    = {52-60},
  title    = {Parametric 3D modeling of a symmetric human body},
  url      = {https://www.sciencedirect.com/science/article/pii/S0097849319300366},
  volume   = {81},
  year     = {2019}
}

@misc{CoCosNet,
  archiveprefix = {arXiv},
  author        = {Pan Zhang and Bo Zhang and Dong Chen and Lu Yuan and Fang Wen},
  eprint        = {2004.05571},
  primaryclass  = {cs.CV},
  title         = {Cross-domain Correspondence Learning for Exemplar-based Image Translation},
  year          = {2020}
}

@misc{CoCosNet2,
  author     = {Xingran Zhou and
                Bo Zhang and
                Ting Zhang and
                Pan Zhang and
                Jianmin Bao and
                Dong Chen and
                Zhongfei Zhang and
                Fang Wen},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2012-02047.bib},
  eprint     = {2012.02047},
  eprinttype = {arXiv},
  journal    = {CoRR},
  timestamp  = {Tue, 08 Nov 2022 08:27:45 +0100},
  title      = {Full-Resolution Correspondence Learning for Image Translation},
  url        = {https://arxiv.org/abs/2012.02047},
  volume     = {abs/2012.02047},
  year       = {2020}
}

 @article{DBLP:journals/corr/abs-1901-00049,
  author     = {Ryota Natsume and
                Shunsuke Saito and
                Zeng Huang and
                Weikai Chen and
                Chongyang Ma and
                Hao Li and
                Shigeo Morishima},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1901-00049.bib},
  eprint     = {1901.00049},
  eprinttype = {arXiv},
  journal    = {CoRR},
  timestamp  = {Tue, 11 Aug 2020 12:06:37 +0200},
  title      = {SiCloPe: Silhouette-Based Clothed People},
  url        = {http://arxiv.org/abs/1901.00049},
  volume     = {abs/1901.00049},
  year       = {2019}
} 

@article{DBLP:journals/corr/abs-1903-06473,
  author     = {Zerong Zheng and
                Tao Yu and
                Yixuan Wei and
                Qionghai Dai and
                Yebin Liu},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1903-06473.bib},
  eprint     = {1903.06473},
  eprinttype = {arXiv},
  journal    = {CoRR},
  timestamp  = {Thu, 29 Oct 2020 15:09:27 +0100},
  title      = {DeepHuman: 3D Human Reconstruction from a Single Image},
  url        = {http://arxiv.org/abs/1903.06473},
  volume     = {abs/1903.06473},
  year       = {2019}
}

@article{DBLP:journals/corr/abs-1908-06544,
  author     = {Abbhinav Venkat and
                Chaitanya Patel and
                Yudhik Agrawal and
                Avinash Sharma},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1908-06544.bib},
  eprint     = {1908.06544},
  eprinttype = {arXiv},
  journal    = {CoRR},
  timestamp  = {Wed, 18 May 2022 16:10:47 +0200},
  title      = {HumanMeshNet: Polygonal Mesh Recovery of Humans},
  url        = {http://arxiv.org/abs/1908.06544},
  volume     = {abs/1908.06544},
  year       = {2019}
}



@inbook{doi:10.1007/978-3-030-58558-7_1,
  author = {Wang, Haoyang and Güler, Riza and Kokkinos, Iasonas and Papandreou, George and Zafeiriou, Stefanos},
  doi    = {10.1007/978-3-030-58558-7_1},
  isbn   = {978-3-030-58557-0},
  month  = {10},
  pages  = {1-17},
  title  = {BLSM: A Bone-Level Skinned Model of the Human Mesh},
  year   = {2020}
}

@article{doi:10.1073/pnas.79.8.2554,
  abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
  author   = {J J Hopfield },
  doi      = {10.1073/pnas.79.8.2554},
  eprint   = {https://www.pnas.org/doi/pdf/10.1073/pnas.79.8.2554},
  journal  = {Proceedings of the National Academy of Sciences},
  number   = {8},
  pages    = {2554-2558},
  title    = {Neural networks and physical systems with emergent collective computational abilities.},
  url      = {https://www.pnas.org/doi/abs/10.1073/pnas.79.8.2554},
  volume   = {79},
  year     = {1982}
}

@misc{glosserca,
  author       = {Glosser.ca},
  howpublished = {Wikimedia Commons},
  note         = {Derived from File:Artificial neural network.svg, CC BY-SA 3.0},
  title        = {Artificial neural network},
  url          = {https://commons.wikimedia.org/w/index.php?curid=24913461},
  year         = {}
}

@article{gradients:1994,
  author  = {Bengio, Y. and Simard, Patrice and Frasconi, Paolo},
  doi     = {10.1109/72.279181},
  journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
  month   = {02},
  pages   = {157-66},
  title   = {Learning long-term dependencies with gradient descent is difficult},
  volume  = {5},
  year    = {1994}
}

@article{gru:2014,
  author     = {Kyunghyun Cho and
                Bart van Merrienboer and
                {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
                Fethi Bougares and
                Holger Schwenk and
                Yoshua Bengio},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/ChoMGBSB14.bib},
  eprint     = {1406.1078},
  eprinttype = {arXiv},
  journal    = {CoRR},
  timestamp  = {Mon, 13 Aug 2018 16:46:44 +0200},
  title      = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical
                Machine Translation},
  url        = {http://arxiv.org/abs/1406.1078},
  volume     = {abs/1406.1078},
  year       = {2014}
}

@misc{http://dprogrammer.org,
  howpublished = {\url{http://dprogrammer.org/rnn-lstm-gru}},
  note         = {Accessed: 2023-06},
  title        = {{dProgrammer lopez}}
}

@article{https://doi.org/10.1002/ase.1718,
  abstract = {Understanding the three-dimensional (3D) nature of the human form is imperative for effective medical practice and the emergence of 3D printing creates numerous opportunities to enhance aspects of medical and healthcare training. A recently deceased, un-embalmed donor was scanned through high-resolution computed tomography. The scan data underwent segmentation and post-processing and a range of 3D-printed anatomical models were produced. A four-stage mixed-methods study was conducted to evaluate the educational value of the models in a medical program. (1) A quantitative pre/post-test to assess change in learner knowledge following 3D-printed model usage in a small group tutorial; (2) student focus group (3) a qualitative student questionnaire regarding personal student model usage (4) teaching faculty evaluation. The use of 3D-printed models in small-group anatomy teaching session resulted in a significant increase in knowledge (P = 0.0001) when compared to didactic 2D-image based teaching methods. Student focus groups yielded six key themes regarding the use of 3D-printed anatomical models: model properties, teaching integration, resource integration, assessment, clinical imaging, and pathology and anatomical variation. Questionnaires detailed how students used the models in the home environment and integrated them with anatomical learning resources such as textbooks and anatomy lectures. In conclusion, 3D-printed anatomical models can be successfully produced from the CT data set of a recently deceased donor. These models can be used in anatomy education as a teaching tool in their own right, as well as a method for augmenting the curriculum and complementing established learning modalities, such as dissection-based teaching. Anat Sci Educ 11: 44–53. © 2017 American Association of Anatomists.},
  author   = {Smith, Claire F. and Tollemache, Nicholas and Covill, Derek and Johnston, Malcolm},
  doi      = {https://doi.org/10.1002/ase.1718},
  eprint   = {https://anatomypubs.onlinelibrary.wiley.com/doi/pdf/10.1002/ase.1718},
  journal  = {Anatomical Sciences Education},
  keywords = {gross anatomy education, medical education, 3D printing, 3D imaging techniques},
  number   = {1},
  pages    = {44-53},
  title    = {Take away body parts! An investigation into the use of 3D-printed anatomical models in undergraduate anatomy education},
  url      = {https://anatomypubs.onlinelibrary.wiley.com/doi/abs/10.1002/ase.1718},
  volume   = {11},
  year     = {2018}
}

@misc{jiang2022humangen,
  archiveprefix = {arXiv},
  author        = {Suyi Jiang and Haoran Jiang and Ziyu Wang and Haimin Luo and Wenzheng Chen and Lan Xu},
  eprint        = {2212.05321},
  primaryclass  = {cs.CV},
  title         = {HumanGen: Generating Human Radiance Fields with Explicit Priors},
  year          = {2022}
}

@article{lstm:1997,
  author  = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  doi     = {10.1162/neco.1997.9.8.1735},
  journal = {Neural computation},
  month   = {12},
  pages   = {1735-80},
  title   = {Long Short-term Memory},
  volume  = {9},
  year    = {1997}
}

@misc{meshcapade,
  author       = {},
  howpublished = {Meshcapade Wiki},
  title        = {SMPL model},
  url          = {https://meshcapade.wiki/SMPL},
  year         = {}
}



@article{pifu,
  author     = {Shunsuke Saito and
                Zeng Huang and
                Ryota Natsume and
                Shigeo Morishima and
                Angjoo Kanazawa and
                Hao Li},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1905-05172.bib},
  eprint     = {1905.05172},
  eprinttype = {arXiv},
  journal    = {CoRR},
  timestamp  = {Tue, 11 Aug 2020 12:06:39 +0200},
  title      = {PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed
                Human Digitization},
  url        = {http://arxiv.org/abs/1905.05172},
  volume     = {abs/1905.05172},
  year       = {2019}
}

@article{pifuhd,
  author     = {Shunsuke Saito and
                Tomas Simon and
                Jason M. Saragih and
                Hanbyul Joo},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2004-00452.bib},
  eprint     = {2004.00452},
  eprinttype = {arXiv},
  journal    = {CoRR},
  timestamp  = {Wed, 08 Apr 2020 17:08:25 +0200},
  title      = {PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution
                3D Human Digitization},
  url        = {https://arxiv.org/abs/2004.00452},
  volume     = {abs/2004.00452},
  year       = {2020}
}

@incollection{pytorch,
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  pages     = {8024--8035},
  publisher = {Curran Associates, Inc.},
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  url       = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
  year      = {2019}
}


@inbook{rnntransformer:2022,
  author = {Katrompas, Alex and Ntakouris, Theodoros and Metsis, Vangelis},
  doi    = {10.1007/978-3-031-09342-5_10},
  isbn   = {978-3-031-09341-8},
  month  = {07},
  pages  = {99-109},
  title  = {Recurrence and Self-attention vs the Transformer for Time-Series Classification: A Comparative Study},
  year   = {2022}
}

@article{scape,
  author  = {Anguelov, Dragomir and Srinivasan, Praveen and Koller, Daphne and Thrun, Sebastian and Rodgers, Jim and Davis, James},
  doi     = {10.1145/1073204.1073207},
  journal = {ACM Transactions on Graphics (TOG)},
  month   = {07},
  pages   = {408-416},
  title   = {SCAPE: Shape completion and animation of people},
  volume  = {24},
  year    = {2005}
}

@inproceedings{SMPL-X:2019,
  author    = {Pavlakos, Georgios and Choutas, Vasileios and Ghorbani, Nima and Bolkart, Timo and Osman, Ahmed A. A. and Tzionas, Dimitrios and Black, Michael J.},
  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {10975--10985},
  title     = {Expressive Body Capture: {3D} Hands, Face, and Body from a Single Image},
  year      = {2019}
}    

@article{SMPL:2015,
  author    = {Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J.},
  journal   = {ACM Trans. Graphics (Proc. SIGGRAPH Asia)},
  month     = oct,
  number    = {6},
  pages     = {248:1--248:16},
  publisher = {ACM},
  title     = {{SMPL}: A Skinned Multi-Person Linear Model},
  volume    = {34},
  year      = {2015}
}

@inproceedings{STAR:2020,
  author    = {Osman, Ahmed A A and Bolkart, Timo and Black, Michael J.},
  booktitle = {European Conference on Computer Vision (ECCV)},
  pages     = {598--613},
  title     = {{STAR}: A Sparse Trained Articulated Human Body Regressor},
  url       = {https://star.is.tue.mpg.de},
  year      = {2020}
}

@inproceedings{weng_humannerf_2022_cvpr,
  author    = {Weng, Chung-Yi and 
               Curless, Brian and 
               Srinivasan, Pratul P. and 
               Barron, Jonathan T. and 
               Kemelmacher-Shlizerman, Ira},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  pages     = {16210-16220},
  title     = {Human{N}e{RF}: Free-Viewpoint Rendering of Moving People From Monocular Video},
  year      = {2022}
}
